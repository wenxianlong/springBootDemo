server:
  port: 8888
  session-timeout: 600s
  servlet:
    context-path: /

spring:
  datasource:
    master:
      # 配置数据源类型
      type:
        com.alibaba.druid.pool.DruidDataSource
      url: jdbc:mysql://localhost:3306/test?useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=UTC&rewriteBatchedStatements=true
      username: root
      password: 123456
      driver-class-name: com.mysql.cj.jdbc.Driver
      # 初始化，最小，最大连接数
      initialSize: 3
      minidle: 3
      maxActive: 18
      # 获取数据库连接等待的超时时间
      maxWait: 60000
      # 配置多久进行一次检测，检测需要关闭的空闲连接 单位毫秒
      timeBetweenEvictionRunsMillis: 60000
      validationQuery: SELECT 1 FROM dual
      # 配置监控统计拦截的filters,去掉后，监控界面的sql无法统计
      filters: stat
    slave:
      jdbc-url: jdbc:sqlserver://192.168.2.155:1433;database=ZujuanMobileSite
      username: zujuan
      password: 21cn.com
      driver-class-name: com.microsoft.sqlserver.jdbc.SQLServerDriver
  redis:
    host: 127.0.0.1
    port: 6379
    password:
    database: 0 # Redis数据库索引（默认为0）
    lettuce:    # 如果使用的jedis 则将lettuce改成jedis即可
      pool:
        max-active: 8   # 最大活跃链接数 默认8
        max-idle: 8     # 最大空闲连接数 默认8
        min-idle: 0     # 最小空闲连接数 默认0
    timeout: 10000

  data:
    elasticsearch:
      #jest: # https://docs.spring.io/spring-boot/docs/2.1.3.RELEASE/reference/htmlsingle/#boot-features-elasticsearch
      #  uris: http://127.0.0.1:9200
      #  read-timeout: 3000
      cluster-name: 'my-application' #默认即为elasticsearch
      cluster-nodes: 127.0.0.1:9300 #配置es节点信息，逗号分隔，如果没有指定，则启动ClientNode
      repositories:
        enabled :true

  level:
    com.zujuan.api.mapper: debug  #打印SQL信息


  kafka:
    # 指定kafka 代理地址，可以多个
    bootstrap-servers: 192.168.10.100:9092
    producer:
      retries: 0
      # 每次批量发送消息的数量
      batch-size: 16384
      # 缓存容量
      buffer-memory: 33554432
      # 指定消息key和消息体的编解码方式
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    consumer:
      # 指定默认消费者group id
      group-id: consumer-tutorial
      auto-commit-interval: 100
      auto-offset-reset: earliest
      enable-auto-commit: true
      # 指定消息key和消息体的编解码方式
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    # 指定listener 容器中的线程数，用于提高并发量
    listener:
      concurrency: 3