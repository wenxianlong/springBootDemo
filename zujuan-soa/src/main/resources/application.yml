server:
  port: 8889
  session-timeout: 600s
  servlet:
    context-path: /

spring:
  datasource:
    master:
      # 配置数据源类型
      type:
        com.alibaba.druid.pool.DruidDataSource
      url: jdbc:mysql://localhost:3306/test?useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=UTC&rewriteBatchedStatements=true
      username: root
      password: 123456
      driver-class-name: com.mysql.cj.jdbc.Driver
      # 初始化，最小，最大连接数
      initialSize: 3
      minidle: 3
      maxActive: 18
      # 获取数据库连接等待的超时时间
      maxWait: 60000
      # 配置多久进行一次检测，检测需要关闭的空闲连接 单位毫秒
      timeBetweenEvictionRunsMillis: 60000
      validationQuery: SELECT 1 FROM dual
      # 配置监控统计拦截的filters,去掉后，监控界面的sql无法统计
      filters: stat
    slave:
      jdbc-url: jdbc:sqlserver://192.168.2.155:1433;database=ZujuanMobileSite
      username: zujuan
      password: 21cn.com
      driver-class-name: com.microsoft.sqlserver.jdbc.SQLServerDriver

  thymeleaf:
    cache: false # 本地开发，关闭缓存
    prefix: classpath:/views/ #调整页面路径

  redis:
    host: 127.0.0.1
    port: 6379
    password:
    database: 0 # Redis数据库索引（默认为0）
    lettuce:    # 如果使用的jedis 则将lettuce改成jedis即可
      pool:
        max-active: 8   # 最大活跃链接数 默认8
        max-idle: 8     # 最大空闲连接数 默认8
        min-idle: 0     # 最小空闲连接数 默认0
    timeout: 10000

  data: #elasticsearch
    elasticsearch:
      #jest: # https://docs.spring.io/spring-boot/docs/2.1.3.RELEASE/reference/htmlsingle/#boot-features-elasticsearch
      #  uris: http://127.0.0.1:9200
      #  read-timeout: 3000
      cluster-name: 'my-application' #默认即为elasticsearch
      cluster-nodes: 127.0.0.1:9300 #配置es节点信息，逗号分隔，如果没有指定，则启动ClientNode
      repositories:
        enabled :true

  kafka:
    # 指定kafka 代理地址，可以多个
    bootstrap-servers: 127.0.0.1:9092
    producer:
      retries: 0
      # 每次批量发送消息的数量
      batch-size: 16384
      # 缓存容量
      buffer-memory: 33554432
      # 指定消息key和消息体的编解码方式
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    consumer:
      enable-auto-commit: true
      group-id: kafka #群组ID
      auto-offset-reset: earliest #启东时接收没有接收到的数据

  dubbo:
    application:
      id: demo-dubbo-provider
      name: zujuan-provider
    server: true
    registry:
      address: zookeeper://127.0.0.1:2181
    protocol:
      name: dubbo
      port: 20881

mybatis:
  configuration:
    map-underscore-to-camel-case: true #配置项：开启下划线到驼峰的自动转换. 作用：将数据库字段根据驼峰规则自动注入到对象属性。

logging:
  config: classpath:logback-spring.xml
  level:
    com.xkw.zujuan.dao.mapper: debug  #打印SQL信息

